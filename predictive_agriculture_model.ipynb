{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0eb4f16-5a99-460d-a5ba-706b7ef0bbe7",
   "metadata": {
    "executionCancelledAt": null,
    "executionTime": 4703,
    "id": "bA5ajAmk7XH6",
    "lastExecutedAt": 1732716780795,
    "lastExecutedByKernel": "5e2a4e39-936b-49da-9606-f0dae1923814",
    "lastScheduledRunId": null,
    "lastSuccessfullyExecutedCode": "import pandas as pd\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.model_selection import train_test_split\nfrom sklearn import metrics\n\n# Load the dataset\ncrops = pd.read_csv(\"soil_measures.csv\")\n\n# Check for missing values\ncrops.isna().sum()\n\n# Check unique values of the target (crop)\ncrops.crop.unique()\n\n# Split into feature and target sets\nX = crops.drop(columns=\"crop\")\ny = crops[\"crop\"]\n\n# Split the data into training and test sets (80% train, 20% test)\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n# Check the shape of the training and test sets\nprint(f\"Training set size: {X_train.shape}, Test set size: {X_test.shape}\")\n# Create a dictionary to store the model performance for each feature\nfeature_performance = {}\n#train a logistic regression model for each feature\nfor feature in [\"N\",\"P\",\"K\",\"ph\"]:\n    log_reg = LogisticRegression(multi_class=\"multinomial\")\n    log_reg.fit(X_train[[feature]],y_train)\n    y_pred = log_reg.predict(X_test[[feature]])\n    #calculate F1 score, the harmonic mean of precision and recallcor use valanced_accuracy_score\n    f1 = metrics.f1_score(y_test, y_pred, average=\"weighted\")\n    feature_performance[feature]=f1\n    print(f\"F1-score for {feature}: {f1}\")\nprint(feature_performance)\n#K produced the best F1score\nbest_predictive_feature = {\"K\": feature_performance[\"K\"]}\nbest_predictive_feature\n# Train the model using all features (N, P, K, pH)\nlog_reg_all = LogisticRegression(multi_class=\"multinomial\")\nlog_reg_all.fit(X_train, y_train)\n\n# Test the model\ny_pred_all = log_reg_all.predict(X_test)\n\n# Calculate the F1 score for the full model (using all features)\nf1_all = metrics.f1_score(y_test, y_pred_all, average=\"weighted\")\nprint(f\"F1-score for model with all features: {f1_all}\")\n\n# Function to predict the crop given soil measures\ndef predict_crop(nitrogen, phosphorus, potassium, ph_value):\n    input_data = pd.DataFrame({\n        \"N\": [nitrogen],\n        \"P\": [phosphorus],\n        \"K\": [potassium],\n        \"ph\": [ph_value]\n    })\n    \n    predicted_crop = log_reg_all.predict(input_data)\n    return predicted_crop[0]\n\n# Example: Predicting the crop for given soil measures\nnitrogen_input = 50  # Example nitrogen level\nphosphorus_input = 30  # Example phosphorus level\npotassium_input = 60  # Example potassium level\nph_input = 6.5  # Example pH level\n\npredicted_crop = predict_crop(nitrogen_input, phosphorus_input, potassium_input, ph_input)\nprint(f\"The recommended crop for the given soil measures is: {predicted_crop}\")\n",
    "outputsMetadata": {
     "0": {
      "height": 101,
      "type": "stream"
     }
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set size: (1760, 4), Test set size: (440, 4)\n",
      "F1-score for N: 0.09149868209906838\n",
      "F1-score for P: 0.14761942909728204\n",
      "F1-score for K: 0.23896974566001802\n",
      "F1-score for ph: 0.04532731061152114\n",
      "{'N': 0.09149868209906838, 'P': 0.14761942909728204, 'K': 0.23896974566001802, 'ph': 0.04532731061152114}\n",
      "F1-score for model with all features: 0.5454206655375167\n",
      "The recommended crop for the given soil measures is: coconut\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, cross_val_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Load the dataset\n",
    "crops = pd.read_csv(\"soil_measures.csv\")\n",
    "\n",
    "# Check for missing values\n",
    "print(crops.isna().sum())\n",
    "\n",
    "# Check unique values of the target (crop)\n",
    "print(crops.crop.unique())\n",
    "\n",
    "# Split into feature and target sets\n",
    "X = crops.drop(columns=\"crop\")\n",
    "y = crops[\"crop\"]\n",
    "\n",
    "# Split the data into training and test sets (80% train, 20% test)\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X,\n",
    "    y,\n",
    "    test_size=0.2,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# Initialize the scaler\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Scale the training and test data\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# --- Step 1: Hyperparameter tuning for Logistic Regression ---\n",
    "param_grid = {\n",
    "    'C': [0.01, 0.1, 1, 10],  # Regularization strength\n",
    "    'solver': ['newton-cg', 'lbfgs', 'liblinear'],  # Solvers\n",
    "}\n",
    "\n",
    "grid_search = GridSearchCV(\n",
    "    LogisticRegression(\n",
    "        multi_class=\"multinomial\",\n",
    "        random_state=42),\n",
    "    param_grid,\n",
    "    cv=5\n",
    ")\n",
    "grid_search.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Best parameters for Logistic Regression\n",
    "print(f\"Best parameters for Logistic Regression: {grid_search.best_params_}\")\n",
    "\n",
    "# Initialize the best Logistic Regression model\n",
    "log_reg_best = grid_search.best_estimator_\n",
    "\n",
    "# Test the model\n",
    "y_pred_log_reg = log_reg_best.predict(X_test_scaled)\n",
    "\n",
    "# Calculate accuracy and F1-score\n",
    "accuracy_log_reg = accuracy_score(y_test, y_pred_log_reg)\n",
    "f1_log_reg = f1_score(y_test, y_pred_log_reg, average=\"weighted\")\n",
    "\n",
    "print(f\"Logistic Regression Accuracy: {accuracy_log_reg * 100:.2f}%\")\n",
    "print(f\"Logistic Regression F1-score: {f1_log_reg:.2f}\")\n",
    "\n",
    "# --- Step 2: Cross-validation for better performance estimate ---\n",
    "cross_val_scores = cross_val_score(\n",
    "    log_reg_best,\n",
    "    X_train_scaled,\n",
    "    y_train,\n",
    "    cv=5\n",
    ")\n",
    "print(f\"Cross-validation scores for Logistic Regression: {cross_val_scores}\")\n",
    "print(f\"Mean cross-validation score: {cross_val_scores.mean():.2f}\")\n",
    "\n",
    "# --- Step 3: Try Random Forest for comparison ---\n",
    "rf_model = RandomForestClassifier(random_state=42)\n",
    "rf_model.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Test the Random Forest model\n",
    "y_pred_rf = rf_model.predict(X_test_scaled)\n",
    "\n",
    "# Calculate accuracy and F1-score for Random Forest\n",
    "accuracy_rf = accuracy_score(y_test, y_pred_rf)\n",
    "f1_rf = f1_score(y_test, y_pred_rf, average=\"weighted\")\n",
    "\n",
    "print(f\"Random Forest Accuracy: {accuracy_rf * 100:.2f}%\")\n",
    "print(f\"Random Forest F1-score: {f1_rf:.2f}\")\n",
    "\n",
    "# --- Step 5: Function to predict crop for new input ---\n",
    "def predict_crop(nitrogen, phosphorus, potassium, ph_value):\n",
    "    input_data = pd.DataFrame({\n",
    "        \"N\": [nitrogen],\n",
    "        \"P\": [phosphorus],\n",
    "        \"K\": [potassium],\n",
    "        \"ph\": [ph_value]\n",
    "    })\n",
    "\n",
    "    predicted_crop = log_reg_best.predict(input_data)  # You can change this to use rf_model or log_reg_weighted\n",
    "    return predicted_crop[0]\n",
    "\n",
    "# Example: Predicting the crop for given soil measures\n",
    "nitrogen_input = 50  # Example nitrogen level\n",
    "phosphorus_input = 30  # Example phosphorus level\n",
    "potassium_input = 60  # Example potassium level\n",
    "ph_input = 6.5  # Example pH level\n",
    "\n",
    "predicted_crop = predict_crop(nitrogen_input, phosphorus_input, potassium_input, ph_input)\n",
    "print(f\"The recommended crop for the given soil measures is: {predicted_crop}\")\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "Welcome to DataCamp Workspaces.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
